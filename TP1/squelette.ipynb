{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## École Polytechnique de Montréal\n",
    "## Département Génie Informatique et Génie Logiciel\n",
    "\n",
    "## INF8460 – Traitement automatique de la langue naturelle - TP1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectifs d'apprentissage: \n",
    "\n",
    "•\tSavoir accéder à un corpus, le nettoyer et effectuer divers pré-traitements sur les données\n",
    "•\tSavoir effectuer une classification automatique des textes pour l’analyse de sentiments\n",
    "•\tEvaluer l’impact des pré-traitements sur les résultats obtenus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Équipe et contributions \n",
    "Veuillez indiquer la contribution effective de chaque membre de l'équipe en pourcentage et en indiquant les modules ou questions sur lesquelles chaque membre a travaillé\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nom Étudiant 1: Luu Thien-Kim (1834378) 1/3%\n",
    "\n",
    "Nom Étudiant 2: Mellouk Souhaila (1835144) 1/3%\n",
    "\n",
    "Nom Étudiant 3: Younes Mourad (1832387) 1/3%\n",
    "\n",
    "Nous avons tous travaillé ensemble sur chaque question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Librairies externes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from typing import List, Literal, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Valeurs globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_path = \"data\"\n",
    "output_path = \"output\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def read_data(path: str) -> Tuple[List[str], List[bool], List[Literal[\"M\", \"W\"]]]:\n",
    "    data = pd.read_csv(path)\n",
    "    inputs = data[\"response_text\"].tolist()\n",
    "    labels = (data[\"sentiment\"] == \"Positive\").tolist()\n",
    "    gender = data[\"op_gender\"].tolist()\n",
    "    return inputs, labels, gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_data = read_data(os.path.join(data_path, \"train.csv\"))\n",
    "test_data = read_data(os.path.join(data_path, \"test.csv\"))\n",
    "\n",
    "train_data = ([text.lower() for text in train_data[0]], train_data[1], train_data[2])\n",
    "test_data = ([text.lower() for text in test_data[0]], test_data[1], test_data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSentiment(data):\n",
    "    sentimentList = []\n",
    "    for sentiment in data:\n",
    "        if sentiment:\n",
    "            sentimentList.append(\"Positive\")\n",
    "        else:\n",
    "            sentimentList.append(\"Negative\")\n",
    "    return sentimentList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pré-traitement et Exploration des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Lecture et prétraitement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Dans cette section, vous devez compléter la fonction preprocess_corpus qui doit être appelée sur les fichiers train.csv et test.csv. La fonction preprocess_corpus appellera les différentes fonctions créées ci-dessous. Les différents fichiers de sortie doivent se retrouver dans le répertoire output.  Chacune des sous-questions suivantes devraient être une ou plusieurs fonctions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join(data_path, \"train.csv\")\n",
    "test_path = os.path.join(data_path, \"test.csv\")\n",
    "\n",
    "train_phrases_path = os.path.join(output_path, \"train_phrases.csv\")\n",
    "test_phrases_path = os.path.join(output_path, \"test_phrases.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowerCases(data):\n",
    "    return ([text.lower() for text in data[0]], data[1], data[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 1) Segmentez chaque corpus en phrases, et stockez-les dans un fichier `nomcorpus`_phrases.csv (une phrase par ligne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/kimluu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/kimluu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"punkt\") \n",
    "nltk.download(\"wordnet\")\n",
    "import csv\n",
    "\n",
    "#segment corpus in sentences\n",
    "#param : path of corpus file\n",
    "#returns path of new file (nomcorpus_phrases.csv)\n",
    "def segmentSentences(path) :\n",
    "    data = lowerCases(read_data(path))\n",
    "    corpus = data[0]\n",
    "    sentiment = getSentiment(data[1])\n",
    "    if not os.path.isdir(output_path) : #create \"output\" directory if it does not exist\n",
    "        try:\n",
    "            os.mkdir(output_path) \n",
    "        except OSError:\n",
    "            print (\"Creation of the directory %s failed\" % path)\n",
    "        else:\n",
    "            print (\"Successfully created the directory %s \" % path)\n",
    "    newFilePath = output_path + '/' + os.path.splitext(os.path.basename(path))[0] + \"_phrases.csv\"\n",
    "    file = open(newFilePath, \"w\")\n",
    "    with open(newFilePath, \"w\") as f: \n",
    "        f.write(\"response_text\" + ',' + \"sentiment\" + ',' + \"op_gender\" +'\\n')\n",
    "        for i in range(len(corpus)) :\n",
    "            sentences = nltk.sent_tokenize(corpus[i])\n",
    "            for sentence in sentences:\n",
    "                sentence = sentence.replace('\"', '\"\"').replace('\"', '\"\"')\n",
    "                f.write('\"'+ sentence +'\"' + ',' + '\"' +sentiment[i]+ '\"'+ ',' + '\"'+data[2][i] + '\"\\n')\n",
    "                \n",
    "    return newFilePath\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 2) Normalisez chaque corpus au moyen d’expressions régulières en annotant les négations avec _Neg L’annotation de la négation doit ajouter un suffixe _NEG à chaque mot qui apparait entre une négation et un signe de ponctuation qui identifie une clause. Exemple : \n",
    "No one enjoys it.  no one_NEG enjoys_NEG it_NEG .\n",
    "\n",
    "I don’t think I will enjoy it, but I might.  i don’t think_NEG i_NEG will_NEG enjoy_NEG it_NEG, but i might."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if the file is about the train or test data\n",
    "#param : path of file\n",
    "#returns path of train or test file\n",
    "def getPath(path) :\n",
    "    if \"train\" in path :\n",
    "        path = train_path\n",
    "    elif \"test\" in path :\n",
    "        path = test_path\n",
    "        \n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "#normalize corpus by adding \"_NEG\" to all the following words of a negation annotation\n",
    "#param : path of file\n",
    "#returns (nomcorpus_negation.csv)\n",
    "def normalize(path) :\n",
    "    with open(path, \"r\") as f :\n",
    "        data = list(f)\n",
    "    \n",
    "    newFilePath = output_path + '/' + os.path.splitext(os.path.basename(getPath(path)))[0] + \"_negation.csv\"\n",
    "    file = open(newFilePath, \"w\")\n",
    "    with open(newFilePath, \"w\") as f:\n",
    "        for sentence in data:\n",
    "            match = re.sub(\"(?i)(?<=not |n't | no )(.*?[,.(?!;]+)\", lambda m: m.group(1).replace(\" \", \"_NEG \")\n",
    "                           .replace(\".\", \"_NEG.\").replace(\",\", \"_NEG,\").replace(\"?\", \"_NEG?\").replace(\"!\", \"_NEG!\")\n",
    "                           .replace(\"(\", \"_NEG(\").replace(\";\", \"_NEG;\"), sentence)\n",
    "            second_match = re.sub(\"(?<=No |NO )(.*?[,.(?!;]+)\", lambda m: m.group(1).replace(\" \", \"_NEG \")\n",
    "                           .replace(\".\", \"_NEG.\").replace(\",\", \"_NEG,\").replace(\"?\", \"_NEG?\").replace(\"!\", \"_NEG!\")\n",
    "                           .replace(\"(\", \"_NEG(\").replace(\";\", \"_NEG;\"), match)\n",
    "            f.write(match)     \n",
    "    return newFilePath\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 3) Segmentez chaque phrase en mots (tokenisation) et stockez-les dans un fichier `nomcorpus`_mots.csv. (Une phrase par ligne, chaque token séparé par un espace, il n’est pas nécessaire de stocker la phrase non segmentée ici) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#tokenize corpus in tokens\n",
    "#param : path of corpus file\n",
    "#returns path of new file (nomcorpus_mots.csv)\n",
    "def tokenize(path) :\n",
    "    data = read_data(path)\n",
    "    corpus = data[0]        \n",
    "    sentiment = getSentiment(data[1])\n",
    "    newFilePath = output_path + '/' + os.path.splitext(os.path.basename(getPath(path)))[0] + \"_mots.csv\"\n",
    "    file = open(newFilePath, \"w\")\n",
    "    with open(newFilePath, \"w\") as f: \n",
    "        f.write(\"response_text\" + ',' + \"sentiment\" + ',' + \"op_gender\" +'\\n')\n",
    "        for i in range(len(corpus)) :\n",
    "            listTokens = nltk.word_tokenize(corpus[i])\n",
    "            tokens = ' '.join(listTokens)\n",
    "            f.write('\"' + tokens + '\"' + ',' + '\"' + sentiment[i]+ '\"'+ ',' + '\"' + data[2][i] + '\"\\n')         \n",
    "    return newFilePath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mots_path = os.path.join(output_path, \"train_mots.csv\")\n",
    "test_mots_path = os.path.join(output_path, \"test_mots.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 4) Lemmatisez les mots et stockez les lemmes dans un fichier `nomcorpus`_lemmes.csv (une phrase par ligne, les lemmes séparés par un espace) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#lemmetize tokens\n",
    "#param : path of corpus file\n",
    "#returns path of new file (nomcorpus_lemmes.csv)\n",
    "def lemmatize(path) :\n",
    "    with open(path, \"r\") as f :\n",
    "        data = list(f)\n",
    "        \n",
    "    newFilePath = output_path + '/' + os.path.splitext(os.path.basename(getPath(path)))[0] + \"_lemmes.csv\"\n",
    "    lemmzer = nltk.WordNetLemmatizer()\n",
    "    \n",
    "    file = open(newFilePath, \"w\")\n",
    "    with open(newFilePath, \"w\") as f: \n",
    "        for sentences in data :\n",
    "            lemmes = [lemmzer.lemmatize(token) for token in sentences.split()]\n",
    "            sentences = ' '.join(lemmes)\n",
    "            f.write(sentences+'\\n')\n",
    "                \n",
    "    return newFilePath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 5) Retrouvez la racine des mots (stemming) en utilisant nltk.PorterStemmer(). Stockez-les dans un fichier `nomcorpus`_stems.csv (une phrase par ligne, les racines séparées par une espace) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#stemmize tokens\n",
    "#param : path of corpus file\n",
    "#returns path of new file (nomcorpus_stems.csv)\n",
    "def stemmize(path) :    \n",
    "\n",
    "    data = read_data(path)\n",
    "    corpus = data[0]        \n",
    "    sentiment = getSentiment(data[1])\n",
    "        \n",
    "    path = getPath(path)\n",
    "    newFilePath = output_path + '/' + os.path.splitext(os.path.basename(path))[0] + \"_stems.csv\"\n",
    "    \n",
    "    stemmer = nltk.PorterStemmer()\n",
    "    \n",
    "    file = open(newFilePath, \"w\")\n",
    "    with open(newFilePath, \"w\") as f:\n",
    "        f.write(\"response_text\" + ',' + \"sentiment\" + ',' + \"op_gender\" +'\\n')\n",
    "        for i in range(len(corpus)) :\n",
    "            stems = [stemmer.stem(token) for token in corpus[i].split()]\n",
    "            sentences = ' '.join(stems)\n",
    "            f.write('\"' + sentences + '\"' + ',' + '\"' + sentiment[i]+ '\"'+ ',' + '\"' + data[2][i] + '\"\\n')\n",
    "                \n",
    "    return newFilePath\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 6) Ecrivez une fonction qui supprime les mots outils (stopwords) du corpus. Vous devez utiliser la liste de stopwords de NLTK ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/kimluu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "stopwords.words(\"english\")\n",
    "\n",
    "#delete stopwords of corpus\n",
    "#param : path of corpus file\n",
    "#returns path of new file (nomcorpus_stopWords.csv)\n",
    "def deleteStopWords(path) :\n",
    "\n",
    "    data = read_data(path)\n",
    "    corpus = data[0]        \n",
    "    sentiment = getSentiment(data[1])\n",
    "        \n",
    "    path = getPath(path)\n",
    "    newFilePath = output_path + '/' + os.path.splitext(os.path.basename(path))[0] + \"_stopWords.csv\"\n",
    "    stopwords_english = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    file = open(newFilePath, \"w\")\n",
    "    with open(newFilePath, \"w\") as f: \n",
    "        f.write(\"response_text\" + ',' + \"sentiment\" + ',' + \"op_gender\" +'\\n')\n",
    "        for i in range(len(corpus)) :\n",
    "                newSentence = [token for token in nltk.word_tokenize(corpus[i]) if token not in stopwords_english]\n",
    "                sentences = ' '.join(newSentence)\n",
    "                if sentences == \"\" :\n",
    "                    sentences = \" \"\n",
    "                f.write('\"' + sentences + '\"' + ',' + '\"' + sentiment[i]+ '\"'+ ',' + '\"' + data[2][i] + '\"\\n')\n",
    "                \n",
    "    return newFilePath\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\n",
    "#### 7) Écrivez une fonction preprocess_corpus(corpus) qui prend un corpus brut stocké dans un fichier.csv, effectue les étapes précédentes, puis stocke le résultat de ces différentes opérations dans un fichier corpus _norm.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "\n",
    "def preprocess_corpus(input_file: str, output_file: str) :\n",
    "    data = read_data(input_file)\n",
    "    results = deleteStopWords(stemmize(lemmatize(tokenize(normalize(segmentSentences(input_file))))))\n",
    "    copyfile(results, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "preprocess_corpus(\n",
    "   os.path.join(data_path, \"train.csv\"), os.path.join(output_path, \"train_norm.csv\")\n",
    ")\n",
    "preprocess_corpus(\n",
    "   os.path.join(data_path, \"test.csv\"), os.path.join(output_path, \"test_norm.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Exploration des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Complétez les fonctions retournant les informations suivantes (une fonction par information, chaque fonction prenant en argument un corpus composé d'une liste de phrases segmentées en tokens(tokenization)) ou une liste de genres et une liste de sentiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checks if the corpus is a list of sentences or tokens\n",
    "#param : corpus (List[List[]])\n",
    "#Returns if the corpus is tokenized or not\n",
    "def isTokenized(corpus) :\n",
    "    for sentences in corpus :\n",
    "        for sentence in corpus :\n",
    "            for l in sentence :\n",
    "                if ' ' in l :\n",
    "                    return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joins tokens to form sentences\n",
    "#param : corpus (List[List[]])\n",
    "#Returns the corpus as a list of documents, that are not tokenizated, but segmented in sentences\n",
    "def getListOfSentences(corpus):\n",
    "    listOfDocs = []\n",
    "    listOfTokens = []\n",
    "    if isTokenized(corpus) :\n",
    "        for sentences in corpus :\n",
    "            for token in sentences :\n",
    "                listOfTokens.append(token)\n",
    "            s = ' '.join(listOfTokens)\n",
    "            s = nltk.sent_tokenize(s)\n",
    "            listOfDocs.append(s)\n",
    "            listOfTokens = []\n",
    "    return listOfDocs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### a. Le nombre total de tokens (mots non distincts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Counts number of tokens\n",
    "#param : corpus (List[List[]])\n",
    "#Returns the count\n",
    "def getNumberOfTokens(corpus):\n",
    "    corpus = getListOfSentences(corpus)\n",
    "    count = 0\n",
    "    for sentences in corpus :\n",
    "        for sentence in sentences :\n",
    "            count = count + len(nltk.word_tokenize(sentence))\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### b. Le nombre total de types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Counts number of distinct tokens\n",
    "#param : corpus (List[List[]])\n",
    "#Returns the count\n",
    "def getNumberOfTypes(corpus):\n",
    "    corpus = getListOfSentences(corpus)\n",
    "    listOfTokens = []\n",
    "    for sentences in corpus :\n",
    "        for sentence in sentences :\n",
    "            tokenList = nltk.word_tokenize(sentence)\n",
    "            for token in tokenList :\n",
    "                listOfTokens.append(token)\n",
    "    listOfTypes = list(dict.fromkeys(listOfTokens))  \n",
    "    return len(listOfTypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### c. Le nombre total de phrases avec négation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Counts number of negative sentences\n",
    "#param : corpus (List[List[]])\n",
    "#Returns the count\n",
    "def getNumberOfNeg(corpus) :\n",
    "    corpus = getListOfSentences(corpus)\n",
    "    numberOfNegativeSentences = 0;\n",
    "    for sentences in corpus:\n",
    "        for sentence in sentences:\n",
    "            if \"_NEG\" in sentence:\n",
    "                numberOfNegativeSentences = numberOfNegativeSentences + 1\n",
    "    return numberOfNegativeSentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### d. Le ratio token/type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Calculates ratio Token/Type\n",
    "#param : corpus (List[List[]])\n",
    "#Returns ratio\n",
    "def getRatioTokenType(corpus):\n",
    "    return float(getNumberOfTokens(corpus)/getNumberOfTypes(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### e. Le nombre total de lemmes distincts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Counts number of distinct lemmes\n",
    "#param : corpus (List[List[]])\n",
    "#Returns the count\n",
    "def getLemmesNumber(corpus):\n",
    "    corpus = getListOfSentences(corpus)\n",
    "    lemmzer = nltk.WordNetLemmatizer()\n",
    "    lemmesList = []\n",
    "    for sentences in corpus :\n",
    "        for sentence in sentences :\n",
    "            lemmes = [lemmzer.lemmatize(token) for token in sentence.split()]\n",
    "            for lemme in lemmes :  \n",
    "                lemmesList.append(lemme)\n",
    "    \n",
    "    lemmesList = list(dict.fromkeys(lemmesList))   \n",
    "    return len(lemmesList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### f. Le nombre total de racines (stems) distinctes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Counts number of distinct stems\n",
    "#param : corpus (List[List[]])\n",
    "#Returns the count\n",
    "def getStemsNumber(corpus):\n",
    "    corpus = getListOfSentences(corpus)\n",
    "    stemmer = nltk.PorterStemmer()\n",
    "    stemsList = []\n",
    "    for sentences in corpus :\n",
    "        for sentence in sentences :\n",
    "            stems = [stemmer.stem(token) for token in sentence.split()]\n",
    "            for stem in stems :\n",
    "                stemsList.append(stem)\n",
    "    stemsList = list(dict.fromkeys(stemsList))     \n",
    "    return len(stemsList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### g. Le nombre total de documents (par classe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Counts number of documents per class (positive or negative)\n",
    "#param : sentiments (List[Bool])\n",
    "#Returns the count of both classes as (countPositive, countNegative)\n",
    "def getNumberOfDocPerClass(sentiments):\n",
    "    countPositive = 0\n",
    "    countNegative = 0\n",
    "    for sentiment in sentiments : \n",
    "        if sentiment : #positif\n",
    "            countPositive = countPositive + 1\n",
    "        else : #negatif\n",
    "            countNegative = countNegative + 1\n",
    "    return countPositive, countNegative\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### h. Le nombre total de phrases (par classe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Counts number of sentences per class (positive or negative)\n",
    "#param : corpus (List[List[]]), sentiments (List[Bool])\n",
    "#Returns the count of both classes as (countSentencesPositives, countSentencesNegatives) \n",
    "def getNumberOfSentencesPerClass(corpus, sentiments) :\n",
    "    corpus = getListOfSentences(corpus)\n",
    "    countSentencesPositives = 0\n",
    "    countSentencesNegatives = 0\n",
    "    for i in range(len(corpus)):\n",
    "        if sentiments[i] : #positive\n",
    "            countSentencesPositives = countSentencesPositives + len(corpus[i])\n",
    "        else : #negative\n",
    "            countSentencesNegatives = countSentencesNegatives + len(corpus[i])          \n",
    "    return countSentencesPositives, countSentencesNegatives   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### i. Le nombre total de phrases avec négation (par classe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Counts number of negative sentences per class (positive or negative)\n",
    "#param : corpus (List[List[]]), sentiments (List[Bool])\n",
    "#Returns the count of both classes as (countNegativeSentencesPositives, countNegativeSentencesNegatives) \n",
    "def getNumberOfNegativeSentences(corpus, sentiments) :\n",
    "    corpus = getListOfSentences(corpus)\n",
    "    countNegativeSentencesPositives = 0\n",
    "    countNegativeSentencesNegatives = 0\n",
    "    i = 0;\n",
    "    for sentences in corpus:\n",
    "        for sentence in sentences:\n",
    "            if sentiments[i]: #positive\n",
    "                if \"_NEG\" in sentence:\n",
    "                    countNegativeSentencesPositives = countNegativeSentencesPositives + 1\n",
    "            else: #negative\n",
    "                if \"_NEG\" in sentence:\n",
    "                    countNegativeSentencesNegatives = countNegativeSentencesNegatives + 1\n",
    "            i = i + 1\n",
    "    return countNegativeSentencesPositives, countNegativeSentencesNegatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### j. Le pourcentage de réponses positives par genre de la personne à qui cette réponse est faite (op_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Calculates the percentages of positive responses per gender (M or W)\n",
    "#param : gender (List[Literal[\"M\", \"W\"]), sentiments (List[Bool])\n",
    "#Returns the percentages as (pourcentageM,pourcentageW) \n",
    "def getPourcentageOfPositiveReponsesPerGender(genders, sentiments):\n",
    "    countPosM = countPosW = 0\n",
    "    iterator = 0\n",
    "    totalResponse = len(sentiments)\n",
    "  \n",
    "    for sentiment in sentiments:\n",
    "        if sentiment :\n",
    "            if genders[0][iterator] == 'M':\n",
    "                countPosM = countPosM + 1\n",
    "            elif genders[0][iterator] == 'W':\n",
    "                countPosW = countPosW + 1\n",
    "        iterator = iterator + 1\n",
    "  \n",
    "    pourcentageW = float(countPosW / totalResponse)\n",
    "    pourcentageM = float(countPosM / totalResponse)\n",
    "  \n",
    "    return pourcentageM, pourcentageW    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 2) Écrivez la fonction explore(corpus, sentiments, genders) qui calcule et affiche toutes ces informations, précédées d'une légende reprenant l’énoncé de chaque question (a,b, ….j)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def explore(\n",
    "    corpus: List[List[str]], sentiments: List[bool], genders: List[Literal[\"M\", \"W\"]]\n",
    ") -> None:\n",
    "    print(\"Le nombre total de tokens (mots non distincts) : \" + getNumberOfTokens(corpus) + \"\\n\")\n",
    "    print(\"Le nombre total de types : \" + getNumberOfTypes(corpus) + \"\\n\")\n",
    "    print(\"Le nombre total de phrases avec négation : \" + getNumberOfNeg(corpus)  + \"\\n\")\n",
    "    print(\"Le ratio token/type : \" + getRatioTokenType(corpus) + \"\\n\")\n",
    "    print(\"Le nombre total de lemmes distincts : \" + getLemmesNumber(corpus) + \"\\n\")\n",
    "    print(\"Le nombre total de racines (stems) distinctes : \" + getStemsNumber(corpus) + \"\\n\")\n",
    "    print(\"Le nombre total de documents (par classe) : \" + getNumberOfDocPerClass(semtiments) + \"\\n\")\n",
    "    print(\"Le nombre total de phrases (par classe) : \" + getNumberOfSentencesPerClass(corpus, sentiments) + \"\\n\")\n",
    "    print(\"Le nombre total de phrases avec négation (par classe) : \" + getNumberOfNegativeSentences(corpus, sentiments)  + \"\\n\")\n",
    "    print(\"Le pourcentage de réponses positives par genre de la personne à qui cette réponse est faite (op_gender) : \" \n",
    "          + getPourcentageOfPositiveReponsesPerGender(sentiments, genders)  + \"\\n\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 3) Calculer une table de fréquence (lemme, rang (le mot le plus fréquent a le rang 1 etc.) ; fréquence (le nombre de fois où il a été vu dans le corpus).  Seuls les N mots les plus fréquents du vocabulaire (N est un paramètre) doivent être gardés. Vous devez stocker les 1000 premières lignes de cette table dans un fichier nommé table_freq.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateFrequences(corpus) :\n",
    "   \n",
    "    corpus = getListOfSentences(corpus)\n",
    "    lemmzer = nltk.WordNetLemmatizer()\n",
    "    lemmesList = []\n",
    "    sorted_dict = {}\n",
    "   \n",
    "    newFilePath = output_path + '/' + \" table_freq.csv\"\n",
    "    file = open(newFilePath, \"w\")\n",
    "    \n",
    "    for sentences in corpus :\n",
    "        for sentence in sentences :\n",
    "            lemmes = [lemmzer.lemmatize(token) for token in sentence.split()]\n",
    "            for lemme in lemmes :\n",
    "                lemmesList.append(lemme)\n",
    "               \n",
    "    for word in lemmesList:\n",
    "        if word not in sorted_dict:\n",
    "            sorted_dict[word] = 0\n",
    "        sorted_dict[word] += 1\n",
    "    words = sorted_dict.items()\n",
    "    sorted_lemme = sorted(words, key= lambda kv: kv[1], reverse=True)\n",
    "    \n",
    "    if(len(sorted_lemme) >= 1000) :\n",
    "        sorted_lemme = (sorted_lemme[:1000])\n",
    "    \n",
    "    with open(newFilePath, \"w\") as f: \n",
    "        f.write(\"word\" + ',' + \"freq\" + '\\n')\n",
    "        for i in range(0, len(sorted_lemme)):\n",
    "            f.write('\"' + sorted_lemme[i][0] + '\"' + ',' + '\"' + str(sorted_lemme[i][1]) + '\"\\n')\n",
    "            \n",
    "    return file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 2. Classification automatique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### a) Classification  automatique avec un modèle sac de mots (unigrammes), Naive Bayes et la régression logistique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "En utilisant la librairie scikitLearn et l’algorithme Multinomial Naive Bayes et Logistic Regression, effectuez la classification des textes avec un modèle sac de mots unigramme pondéré avec TF-IDF.  Vous devez entrainer chaque modèle sur l’ensemble d’entrainement et le construire à partir de votre fichier corpus_train.csv. \n",
    "\n",
    "Construisez et sauvegardez votre modèle sac de mots avec les données d’entrainement en testant les pré-traitements suivants (séparément et en combinaison): tokenisation, lemmatisation, stemming, normalisation des négations, et suppression des mots outils. Vous ne devez garder que la combinaison d’opérations qui vous donne les meilleures performances sur le corpus de test. Indiquez dans un commentaire les pré-traitements qui vous amènent à votre meilleure performance (voir la section 3 – évaluation). Il est possible que la combinaison optimale ne soit pas la même selon que vous utilisiez la régression logistique ou Naive Bayes. On s’attend à avoir deux modèles optimaux, un pour Naive Bayes, et un avec régression logistique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataSet(train_csv, test_csv):\n",
    "    trainPath = os.path.join(output_path, train_csv)\n",
    "    testPath = os.path.join(output_path, test_csv)\n",
    "    \n",
    "    trainData = read_data(trainPath)\n",
    "    testData = read_data(testPath)\n",
    "    \n",
    "    return trainData,testData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, testing_data = getDataSet(\"train_phrases.csv\", \"test_phrases.csv\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def naiveBayes(train_data, test_data):\n",
    "    vectorizer = TfidfVectorizer()    \n",
    "    vectors = vectorizer.fit_transform(train_data[0])\n",
    "    clf = MultinomialNB(alpha=0.5)\n",
    "    clf.fit(vectors, train_data[1])\n",
    "    \n",
    "    vectors_test = vectorizer.transform(test_data[0])\n",
    "    y_pred = clf.predict(vectors_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False    0.78191   0.29697   0.43045       495\n",
      "        True    0.81732   0.97434   0.88895      1598\n",
      "\n",
      "    accuracy                        0.81414      2093\n",
      "   macro avg    0.79962   0.63566   0.65970      2093\n",
      "weighted avg    0.80895   0.81414   0.78052      2093\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Optimal combination for Naive Bayes\n",
    "train_bayes = deleteStopWords(normalize(train_phrases_path))\n",
    "test_bayes = deleteStopWords(normalize(test_phrases_path))\n",
    "\n",
    "training_data_bayes, testing_data_bayes = getDataSet(os.path.basename(train_bayes), os.path.basename(test_bayes) )\n",
    "y_pred_bayes = naiveBayes(training_data_bayes, testing_data_bayes)\n",
    "print(classification_report(testing_data[1], y_pred_bayes, digits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Régression Logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def logisticsRegression(train_data, test_data, regParamC):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectors = vectorizer.fit_transform(train_data[0])\n",
    "    model = LogisticRegression(C=regParamC)\n",
    "    model.fit(vectors, train_data[1])\n",
    "    \n",
    "    vectors_test = vectorizer.transform(test_data[0])\n",
    "    y_pred = model.predict(vectors_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False    0.72764   0.36162   0.48313       495\n",
      "        True    0.82891   0.95807   0.88882      1598\n",
      "\n",
      "    accuracy                        0.81701      2093\n",
      "   macro avg    0.77828   0.65984   0.68598      2093\n",
      "weighted avg    0.80496   0.81701   0.79288      2093\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Optimal combination for Logistics Regression\n",
    "train_logisticsRegression = lemmatize(tokenize(normalize(train_phrases_path)))\n",
    "test_logisticsRegression = lemmatize(tokenize(normalize(test_phrases_path)))\n",
    "\n",
    "training_data_logistics, testing_data_logistics = getDataSet(os.path.basename(train_logisticsRegression), os.path.basename(test_logisticsRegression))\n",
    "y_pred_logisticsRegression = logisticsRegression(training_data, testing_data, 1.0 )\n",
    "print(classification_report(testing_data[1], y_pred_logisticsRegression, digits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "###  b) Autre représentation pour l’analyse de sentiments et classification automatique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "On vous propose maintenant d’utiliser une nouvelle représentation de chaque document à classifier.\n",
    "Vous devez créer à partir de votre corpus la table suivante :\n",
    "\n",
    "| Vocabulaire | Freq-positive | Freq-négative |\n",
    "|-------------|---------------|---------------|\n",
    "| happy | 10 | 1 |\n",
    "| ... | ... | ... |\n",
    "\n",
    "Où :\n",
    "\n",
    "• Vocabulaire représente tous les types (mots uniques) de votre corpus d’entrainement\n",
    "\n",
    "• Freq-positive : représente la somme des fréquences du mot dans tous les documents de la classe positive\n",
    "\n",
    "• Freq-négative : représente la somme des fréquences du mot dans tous les documents de la classe négative\n",
    "\n",
    "Notez qu’en Python, vous pouvez créer un dictionnaire associant à tout (mot, classe) une fréquence.\n",
    "Ensuite il vous suffit de représenter chaque document par un vecteur à 3 dimensions dont le premier élément représente un biais (initialisé à 1), le deuxième élément représente la somme des fréquences positives (freq-pos) de tous les mots uniques (types) du document et enfin le troisième élément représente la somme des fréquences négative (freq-neg) de tous les mots uniques du document. \n",
    "\n",
    "En utilisant cette représentation ainsi que les pré-traitements suggérés, trouvez le meilleur modèle possible en testant la régression logistique et Naive Bayes. Vous ne devez fournir que le code de votre meilleur modèle dans votre notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Creates a dataFrame with Vocabulaire, Freq-positive and Freq-négativ\n",
    "#param : corpus\n",
    "#Returns the dataFrame\n",
    "def getTableOfFrequencies(corpus) :\n",
    "    dictionnary = {}\n",
    "    listOfTokens = []\n",
    "    data = []\n",
    "\n",
    "    for i in range(len(corpus[0])) :\n",
    "        tokenList = nltk.word_tokenize(corpus[0][i])\n",
    "        for token in tokenList :\n",
    "            if token == \" \" :\n",
    "                token = \"1\"\n",
    "            listOfTokens.append(token)\n",
    "            key = (token, corpus[1][i])\n",
    "            if key in dictionnary : #if the key already exists in dic, increment frequency\n",
    "                dictionnary[key] = dictionnary[key] + 1\n",
    "            else : #if not, create key and initiate frequency to 1\n",
    "                dictionnary.update({key : 1})\n",
    "    listOfTokens = list(dict.fromkeys(listOfTokens)) #list of distinct tokens\n",
    "\n",
    "    for token in listOfTokens :\n",
    "        freq_pos = 0\n",
    "        freq_neg = 0\n",
    "        if (token, True) in dictionnary and (token, False) in dictionnary :\n",
    "            freq_pos = dictionnary[token, True]\n",
    "            freq_neg = dictionnary[token, False]\n",
    "        if (token, True) in dictionnary and (token, False) not in dictionnary :\n",
    "            freq_pos = dictionnary[token, True]\n",
    "        if (token, True) not in dictionnary and (token, False) in dictionnary :\n",
    "            freq_neg = dictionnary[token, False]\n",
    "        data.append([token, freq_pos, freq_neg])    \n",
    "\n",
    "    return pd.DataFrame(data, columns=[\"Vocabulaire\", \"Freq-positive\", \"Freq-négative\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vocabulaire</th>\n",
       "      <th>Freq-positive</th>\n",
       "      <th>Freq-négative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thanks</td>\n",
       "      <td>95</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>back</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>!</td>\n",
       "      <td>776</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yep</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>,</td>\n",
       "      <td>355</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4156</th>\n",
       "      <td>tingle</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4157</th>\n",
       "      <td>jumping</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4158</th>\n",
       "      <td>ship</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4159</th>\n",
       "      <td>fiber</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4160</th>\n",
       "      <td>mathematician</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4161 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Vocabulaire  Freq-positive  Freq-négative\n",
       "0            thanks             95              2\n",
       "1              back             41              6\n",
       "2                 !            776            105\n",
       "3               yep              1              0\n",
       "4                 ,            355            176\n",
       "...             ...            ...            ...\n",
       "4156         tingle              1              0\n",
       "4157        jumping              1              0\n",
       "4158           ship              1              0\n",
       "4159          fiber              1              0\n",
       "4160  mathematician              1              0\n",
       "\n",
       "[4161 rows x 3 columns]"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getTableOfFrequencies(testing_data_logistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 3. Évaluation et discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### a) Pour déterminer la performance de vos modèles, vous devez tester vos modèles de classification sur l’ensemble de test et générer vos résultats pour chaque modèle dans une table avec les métriques suivantes : Accuracy et pour chaque classe, la précision, le rappel et le F1 score. On doit voir cette table générée dans votre notebook avec la liste de vos modèles de la section 2 et leurs performances respectives. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.83      0.25      0.38       495\n",
      "        True       0.81      0.98      0.89      1598\n",
      "\n",
      "    accuracy                           0.81      2093\n",
      "   macro avg       0.82      0.62      0.63      2093\n",
      "weighted avg       0.81      0.81      0.77      2093\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_bayes = naiveBayes(training_data, testing_data)\n",
    "print(classification_report(testing_data[1], y_pred_bayes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.73      0.36      0.48       495\n",
      "        True       0.83      0.96      0.89      1598\n",
      "\n",
      "    accuracy                           0.82      2093\n",
      "   macro avg       0.78      0.66      0.69      2093\n",
      "weighted avg       0.80      0.82      0.79      2093\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_regression = logisticsRegression(training_data, testing_data,1.0)\n",
    "print(classification_report(testing_data[1], y_pred_regression))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### b) Générez un graphique qui représente la performance moyenne (mean accuracy – 10 Fold cross-validation) de vos différents modèles par tranches de 500 textes sur l’ensemble d’entrainement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseClassification(models):\n",
    "    vec = TfidfVectorizer().fit_transform(train_data[0])\n",
    "    if models == 'LR' :   \n",
    "        model = LogisticRegression(C=1.0)\n",
    "        model.fit(vec, train_data[1])\n",
    "    if models == 'NB' :    \n",
    "        model = MultinomialNB(alpha=0.5)\n",
    "        model.fit(vec, train_data[1])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyFoldCrossValidation(model, X_train, Y_train):\n",
    "    KFold = RepeatedKFold(n_splits=10)\n",
    "    accuracies = cross_val_score(model, X_train, Y_train,cv=KFold)\n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_abs = []\n",
    "Maccuracies_LogisticRegression = []\n",
    "Maccuracies_NaiveBayes = []\n",
    "\n",
    "def findMeanAccuracy():\n",
    "    accuracy_LogisticRegression = []\n",
    "    accuracy_NaiveBayes = []\n",
    "    k = 0\n",
    "    \n",
    "    vec = TfidfVectorizer()\n",
    "\n",
    "    for i in range(0, int(len (train_data[0]) / 500)):\n",
    "        train = train_data[0][0+k : 500 +k]\n",
    "        test = train_data[1][0+k : 500 +k]\n",
    "        \n",
    "        vecTransformation = vec.fit_transform(train)\n",
    "        X_training, X_testing, Y_training, Y_testing = train_test_split(vecTransformation, test)\n",
    "        \n",
    "        accuracy_LogisticRegression = applyFoldCrossValidation(chooseClassification('LR'),X_training,Y_training)\n",
    "        accuracy_NaiveBayes = applyFoldCrossValidation(chooseClassification('NB'),X_training,Y_training)\n",
    "        Maccuracies_LogisticRegression.append(accuracy_LogisticRegression.mean())\n",
    "        Maccuracies_NaiveBayes.append(accuracy_NaiveBayes.mean())\n",
    "        X_abs.append(k)\n",
    "        k = k+ 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findMeanAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateMeanAccuranciesGraph():\n",
    "    plt.figure(figsize=(40, 20))\n",
    "    plt.suptitle('Graphique de la performance moyenne', fontsize=40, fontweight='bold')\n",
    "    plt.plot(X_abs, Maccuracies_LogisticRegression)\n",
    "    plt.plot(X_abs, Maccuracies_NaiveBayes)\n",
    "    plt.xticks(X_abs, fontsize=25)\n",
    "    plt.yticks( fontsize=25)\n",
    "    plt.legend([\"Logistic Regression\", \"Naive Bayes\"], fontsize=40)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GenerateMeanAccuranciesGraph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### c) Que se passe-t-il lorsque le paramètre de régularisation de la régression logisque (C) est augmenté ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(\"For C = 1.0\")\n",
    "y_pred_regression = logisticsRegression(train_data, test_data,1.0)\n",
    "print(classification_report(test_data[1], y_pred_regression) + \"\\n\")\n",
    "\n",
    "print(\"For C = 2.0\")\n",
    "y_pred_regression = logisticsRegression(train_data, test_data,2.0)\n",
    "print(classification_report(test_data[1], y_pred_regression) + \"\\n\")\n",
    "\n",
    "print(\"For C = 5.0\")\n",
    "y_pred_regression = logisticsRegression(train_data, test_data,5.0)\n",
    "print(classification_report(test_data[1], y_pred_regression))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plus le paramètre de régulation logistique (C) augmente, plus la vraisemblance baisse.\n",
    "\n",
    "Métrique précision :\n",
    "Pour ce qui en est de la précision du sentiment négatif, elle diminue plus le C augmente \n",
    "contaiement à la précision du sentiment positif qui reste relativement stable soit env 0.86\n",
    "\n",
    "Métrique recall :\n",
    "Pour ce qui en est du rappel du sentiment négatif, il augmente plus le C augmente \n",
    "contaiement au rappel du sentiment positif qui reste relativement stable soit env 0.95\n",
    "\n",
    "Métrique f1:\n",
    "Quant au f1, il reste relativement constant avec une légère variation pour la classe False quand C= 5.0\n",
    "\n",
    "La précision des moyennes micro et macro sont relativement semblables et ne\n",
    "varient pas quand le C augmente : 0.83 et 0.84 pour C=1, 0.82 et 0.84 pour C=2, 0.81 et 0.84 pour C=5\n",
    "Ceci reflète que l'ensemble des données est relativiement balancées entre les 2 classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyse et discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) En considérant les deux types de représentations, répondez aux question suivantes en reportant la question dans le notebook et en inscrivant votre réponse:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Quel est l’impact de l’annotation de la négation ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour ce qui en est de uniquement appliquer l'annotation de la négation, le modèle de la regression\n",
    "logistique présente un meilleur score pour le sentinement négatif : soit 0.47936 contre 0.38006\n",
    "pour Naive Bayes. Pour le sentiment positif, le score est relativement le même : soit 0.88748 \n",
    "contre 0.88770 pour Naive Bayes.\n",
    "\n",
    "En combinant les étapes de pré-traitement, on a pu remarquer que l'ajout de la négation\n",
    "améliore légèrement notre score pour le sentiment négatif pour les 2 modèles. À titre d'exemple :\n",
    "\n",
    "|--------------------|-----------------------------------------|----------------------------------------\n",
    "                    |                 NAIVE BAYES             |           REGRESSION LOGISTIQUE\n",
    "|--------------------|--------------------|--------------------|--------------------|--------------------\n",
    "  PRÉ-TRAITEMENT    |        FAUX        |       VRAI         |        FAUX        |        VRAI\n",
    "|--------------------|--------------------|--------------------|--------------------|--------------------\n",
    "stopWords           |      0.40964       |   0.88870          |    0.41752         |      0.88603\n",
    "|--------------------|--------------------|--------------------|--------------------|--------------------\n",
    "stopWords, NEG.     |      0.43045       |   0.88895          |    0.42136         |      0.88520\n",
    "|--------------------|--------------------|--------------------|--------------------|--------------------\n",
    "lemmes, tokenize    |      0.38305       |   0.88926          |    0.47203         |      0.88792           \n",
    "|--------------------|--------------------|--------------------|--------------------|--------------------\n",
    "lemmes,tokenize, NEG|      0.39880       |   0.88605          |    0.47989         |      0.88721        \n",
    "|--------------------|--------------------|--------------------|--------------------|--------------------\n",
    "tokenize            |      0.37246       |   0.88695          |    0.47425         |     0.88747           \n",
    "|--------------------|--------------------|--------------------|--------------------|--------------------\n",
    "tokenize, NEG       |      0.39269       |   0.88694          |    0.47268         |      0.88825        \n",
    "|--------------------|--------------------|--------------------|--------------------|--------------------\n",
    "\n",
    "L'ajout du _NEG premet de mieux différencer et d'avoir un meilleur résultat quant au sentiment\n",
    "négatif et positif. En général, le modèle de la Regression logistique donne de meilleur score\n",
    "pour les sentiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) La suppression des stopwords est-elle une bonne idée pour l’analyse de sentiments ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "La suppression des stopwords améliore l'analyse de sentiments lorsqu'on\n",
    "utilise Naive Bayes. Cependant, la suppression des stopwords \n",
    "n'est pas une bonne idée pour l'analyse de sentiments lorsqu'on utilise \n",
    "la régression logistique puisque nos scores baissent comme on peut le \n",
    "voir ci-dessous: \n",
    "\n",
    "--------------------|-----------------------------------------|----------------------------------------\n",
    "                    |                 NAIVE BAYES             |           REGRESSION LOGISTIQUE\n",
    "--------------------|--------------------|--------------------|--------------------|--------------------\n",
    "  PRÉ-TRAITEMENT    |        FAUX        |       VRAI         |        FAUX        |        VRAI\n",
    "--------------------|--------------------|--------------------|--------------------|--------------------\n",
    "NEG                 |      0.39697       |   0.88712          |    0.47476         |      0.88850\n",
    "--------------------|--------------------|--------------------|--------------------|--------------------\n",
    "stopWords, NEG      |     0.43045        |   0.88895          |    0.42136         |      0.88520\n",
    "--------------------|--------------------|--------------------|--------------------|--------------------\n",
    "tokenize            |      0.37246       |   0.88695          |    0.47425         |      0.88747          \n",
    "--------------------|--------------------|--------------------|--------------------|--------------------\n",
    "stopWords,Tokenize  |      0.40964       |   0.88870          |    0.41752         |      0.88603        \n",
    "--------------------|--------------------|--------------------|--------------------|--------------------\n",
    "lemmatize           |      0.37677       |   0.88814          |    0.47490         |      0.88779        \n",
    "--------------------|--------------------|--------------------|--------------------|--------------------\n",
    "stopWords,lemmes    |      0.40785       |   0.88876          |    0.42319         |      0.88616       \n",
    "--------------------|--------------------|--------------------|--------------------|--------------------\n",
    "\n",
    "On remarque donc qu'on passe bien de 0.39697 à 0.43045 pour le sentiment négatif lorsqu'on supprime\n",
    "les stopwords suite à la normalisation en utilisant Naive Bayes. Le sentiment positif varie très\n",
    "sensiblement (d'environ 0,001). \n",
    "Lorsqu'on utilise la régression logistique, le score du sentiment négatif baisse considérablement \n",
    "puisqu'il chute par exemple de 0.47476 à 0.42136, suite à la suppression des stopwords après\n",
    "une normalisation. Ceci est également le cas de n'importe quel pré-traitement auquel on ajoute\n",
    "la suppression des stopwords. Toutefois, le sentiment positif reste relativement constant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Le stemming et/ou la lemmatisation sont-ils souhaitables dans le cadre de l’analyse de sentiments ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le stemming/lemmatisation sont souhaitables dans le cadre d'analyse de sentiments, et \n",
    "augmente les scores lors de l'analyse des sentiments en utilisant Les 2 modèles. Toutefois\n",
    "la variation n'est pas très significative :\n",
    "\n",
    "--------------------|-----------------------------------------|----------------------------------------\n",
    "                    |                 NAIVE BAYES             |           REGRESSION LOGISTIQUE\n",
    "--------------------|--------------------|--------------------|--------------------|--------------------\n",
    "  PRÉ-TRAITEMENT    |        FAUX        |       VRAI         |        FAUX        |        VRAI\n",
    "--------------------|--------------------|--------------------|--------------------|--------------------\n",
    "tokenize            |      0.37246       |   0.88695          |    0.47425         |      0.88747\n",
    "--------------------|--------------------|--------------------|--------------------|--------------------\n",
    "stems,tokenize      |      0.38640       |   0.88782          |    0.48276         |      0.88636\n",
    "--------------------|--------------------|--------------------|--------------------|--------------------\n",
    "stopWords           |      0.40964       |   0.88870          |    0.41752         |     0.88603         \n",
    "--------------------|--------------------|--------------------|--------------------|--------------------\n",
    "stopWords,lemmes    |      0.40785       |   0.88876          |    0.42319         |      0.88616       \n",
    "--------------------|--------------------|--------------------|--------------------|--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Contribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complétez la section en haut du notebook indiquant la contribution de chaque membre de l’équipe en indiquant ce qui a été effectué par chaque membre et le pourcentage d’effort du membre dans le TP. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nom Étudiant 1: Luu Thien-Kim (1834378) 1/3%\n",
    "\n",
    "Nom Étudiant 2: Mellouk Souhaila (1835144) 1/3%\n",
    "\n",
    "Nom Étudiant 3: Younes Mourad (1832387) 1/3%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
